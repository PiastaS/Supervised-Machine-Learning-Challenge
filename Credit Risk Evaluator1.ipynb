{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "train_df = pd.read_csv(Path('Resources/2019loans.csv'))\n",
    "test_df = pd.read_csv(Path('Resources/2020Q1loans.csv'))\n",
    "# Convert categorical data to numeric and separate target feature for training data\n",
    "Yes_No_dict = {'Y':1,'N':0}\n",
    "train_df2 = train_df.replace({'hardship_flag':Yes_No_dict, 'debt_settlement_flag':Yes_No_dict})\n",
    "Home_ownership_dict = {'ANY':0,'RENT':1,'MORTGAGE':2,'OWN':3}\n",
    "train_df3 = train_df2.replace({'home_ownership':Home_ownership_dict})\n",
    "verification_dict = {'Not Verified':0,'Source Verified':1,'Verified':1}\n",
    "train_df4 = train_df3.replace({'verification_status':verification_dict})\n",
    "Loan_status_dict = {'low_risk':1,'high_risk':0}\n",
    "train_df5 = train_df4.replace({'loan_status':Loan_status_dict})\n",
    "Initial_list_status_dict = {'w':0,'f':1}\n",
    "train_df6 = train_df5.replace({'initial_list_status':Initial_list_status_dict})\n",
    "Application_Type_dict = {'Individual':1,'Joint App':0}\n",
    "train_df7 = train_df6.replace({'application_type':Application_Type_dict})\n",
    "\n",
    "train_df8 = train_df7.drop(['index','pymnt_plan'],axis='columns')\n",
    "\n",
    "file_path = Path('Resources/cleaned_2019_credit_data.csv')\n",
    "train_df8.to_csv(file_path, index=False)\n",
    "train_df9 = train_df8.drop(['Unnamed: 0'],axis='columns')\n",
    "train_df9.head()\n",
    "\n",
    "X_train = train_df9.drop('loan_status', axis=1)\n",
    "y_train = train_df9['loan_status'].values\n",
    "print(X_train.select_dtypes(include=[object]))\n",
    "Empty DataFrame\n",
    "Columns: []\n",
    "Index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n",
    "\n",
    "[12180 rows x 0 columns]\n",
    "# Convert categorical data to numeric and separate target feature for testing data\n",
    "test_df2 = test_df.replace({'hardship_flag':Yes_No_dict, 'debt_settlement_flag':Yes_No_dict})\n",
    "test_df3 = test_df2.replace({'home_ownership':Home_ownership_dict})\n",
    "test_df4 = test_df3.replace({'verification_status':verification_dict})\n",
    "test_df5 = test_df4.replace({'loan_status':Loan_status_dict})\n",
    "test_df6 = test_df5.replace({'initial_list_status':Initial_list_status_dict})\n",
    "test_df7 = test_df6.replace({'application_type':Application_Type_dict})\n",
    "\n",
    "test_df8 = test_df7.drop(['index','pymnt_plan'],axis='columns')\n",
    "\n",
    "file_path = Path('Resources/cleaned_2020_credit_data.csv')\n",
    "test_df8.to_csv(file_path, index=False)\n",
    "test_df9 = test_df8.drop(['Unnamed: 0'],axis='columns')\n",
    "test_df9.head()\n",
    "loan_amnt\tint_rate\tinstallment\thome_ownership\tannual_inc\tverification_status\tloan_status\tdti\tdelinq_2yrs\tinq_last_6mths\t...\tpct_tl_nvr_dlq\tpercent_bc_gt_75\tpub_rec_bankruptcies\ttax_liens\ttot_hi_cred_lim\ttotal_bal_ex_mort\ttotal_bc_limit\ttotal_il_high_credit_limit\thardship_flag\tdebt_settlement_flag\n",
    "0\t40000.0\t0.0819\t814.70\t2\t140000.0\t0\t1\t19.75\t0.0\t1.0\t...\t97.7\t0.0\t0.0\t0.0\t527975.0\t70914.0\t74600.0\t99475.0\t0\t0\n",
    "1\t6000.0\t0.1524\t208.70\t1\t55000.0\t0\t1\t11.52\t2.0\t0.0\t...\t66.7\t0.0\t0.0\t0.0\t34628.0\t23460.0\t5900.0\t23628.0\t0\t0\n",
    "2\t3600.0\t0.1695\t128.27\t1\t42000.0\t0\t1\t6.74\t0.0\t0.0\t...\t100.0\t0.0\t0.0\t0.0\t23100.0\t19183.0\t7300.0\t15000.0\t0\t0\n",
    "3\t20000.0\t0.1524\t478.33\t1\t100000.0\t0\t1\t12.13\t0.0\t2.0\t...\t100.0\t50.0\t0.0\t0.0\t56481.0\t43817.0\t13800.0\t35981.0\t0\t0\n",
    "4\t3600.0\t0.1240\t120.27\t1\t50000.0\t0\t1\t16.08\t0.0\t3.0\t...\t100.0\t25.0\t0.0\t0.0\t45977.0\t32448.0\t21000.0\t24977.0\t0\t0\n",
    "5 rows Ã— 83 columns\n",
    "\n",
    "# add missing dummy variables to testing set\n",
    "test_df10 = pd.get_dummies(test_df9)\n",
    "\n",
    "X_test = test_df10.drop('loan_status', axis=1)\n",
    "y_test = test_df10['loan_status'].values\n",
    "# Train the Logistic Regression model on the unscaled data and print the model score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver='lbfgs',max_iter=200)\n",
    "classifier.fit(X_train, y_train)\n",
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")\n",
    "Training Data Score: 0.6524630541871921\n",
    "Testing Data Score: 0.5157379838366652\n",
    "C:\\Users\\GPSchool\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
    "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
    "\n",
    "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
    "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "Please also refer to the documentation for alternative solver options:\n",
    "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
    "# Train a Random Forest Classifier model and print the model score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=500).fit(X_train, y_train)\n",
    "print(f'Training Score: {clf.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test, y_test)}')\n",
    "Training Score: 1.0\n",
    "Testing Score: 0.6399404508719694\n",
    "# Scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "# Train the Logistic Regression model on the scaled data and print the model score\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "print(f\"Training Data Score: {classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test_scaled, y_test)}\")\n",
    "Training Data Score: 0.7060755336617406\n",
    "Testing Data Score: 0.6601446193109315\n",
    "C:\\Users\\GPSchool\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
    "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
    "\n",
    "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
    "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "Please also refer to the documentation for alternative solver options:\n",
    "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
    "# Train a Random Forest Classifier model on the scaled data and print the model score\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')\n",
    "Testing Score: 0.5"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
